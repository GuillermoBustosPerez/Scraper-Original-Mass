---
title: 'Scraper original mass: a different approach and its wide range implementation'
author: "Guillermo Bustos-Pérez"
output:
  md_document:
    variant: gfm
bibliography: "References.bib"
csl: "plos-one.csl"
link-citations: true
linkcolor: blue
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# **Scraper original mass: a different approach and its wide range implementation**   

Guillermo Bustos-Pérez $^{(1,2,3)}$

$^{(1)}$ Department of Human Origins, Max Planck Institute for Evolutionary Anthropology, Leipzig.  
$^{(2)}$ Institut Català de Paleoecologia Humana i Evolució Social (IPHES-CERCA), Tarragona, Spain.  
$^{(3)}$ Departament d’Història i Història de l’Art, Universitat Rovira i Virgili, Tarragona, Spain.  


<div align="justify">   

## **Abstract**   

Predicting the original mass of a retouched scraper has long been a major goal in lithic analysis. It is commonly linked to lithic technological organization of past societies along with notions of stone tool general morphology, standardization through the reduction process, use life, and site occupation patterns. In order to obtain a prediction of original stone tool mass, previous studies have focused on attributes that would remain constant or unaltered through retouch episodes. However, these approaches have provided limited success for predictions and have also remained untested in the framework of successive resharpening episodes. In the research presented here, a set of experimentally knapped flint flakes were successively resharpened as scraper types. After each resharpening episode, four attributes were recorded (scraper mass, height of retouch, maximum thickness and the GIUR index). Four machine learning models were trained using these variables in order to estimate the mass of the flake prior to any retouch. A Random Forest model provided the best results with an r2 value of 0.97 when predicting original flake mass, and a r2 value of 0.84 when predicting percentage of mass lost by retouch.  The Random Forest model has been integrated into an open source and free to use Shiny app. This allows for the wide spread implementation of a highly precise machine learning model for predicting initial mass of flake blanks successively retouched into scrapers.    

**Key words:** experimental archaeology; lithic reduction; flake mass; machine learning.   

## **Introduction**   

Scrapers are some of the most common lithic implements among archaeological lithic assemblages. They are present from the first Oldowan stone tools [@barsky_early_2011; @sahnouni_further_2002; @semaw_26-million-year-old_2003] through to modern ethnographic studies of hunter gatherers [@casamiquela_temas_1978; @gallagher_contemporary_1977; @shott_measuring_2007; @sillitoe_living_2003]. The "reduction model" [@dibble_middle_1995; @dibble_interpretation_1987] suggests that some stone tools (including scrapers) can represent different stages of reuse and modification through retouch. When considering scrapers within the reduction model, an integral concept is that of curation. The initial definition of curation included a series of behavioral patterns related to provisioning strategies [@binford_organization_1979; @renfrew_interassemblage_1973]. However, further authors included into curation behavioral strategies such as tool transport, utilization in a wide range of tasks, anticipated production, hafting, and recycling (after the original tool had been discarded). An alternative definition of curation was proposed by Shott [@shott_exegesis_1996; @shott_tool-class_1989], who defined curation as “the ratio of realized to potential utility”. This new approach to the definition of curation has important implications for lithic analysis and the study of lithic technological organization since it transforms curation into a continuous variable [@shott_exegesis_1996]. Given this new definition, and in the framework of the reduction model, the amount of mass lost by a lithic artifact by reuse/resharpening will be equivalent to its ratio of curation. Both variables (amount in grams and percentage of mass lost by a stone tool) can be empirically calculated in experimental contexts and estimated in archaeological contexts. The presence of scrapers and their curation relates to several aspects of the organization of lithic technology of past societies [@clarkson_holocene_2002; @glauberman_late_2020; @andrefsky_construction_2008; @kuhn_unpacking_1991; @shott_costs_2018; @shott_use_2017]. Amount of curation affects the shape of stone tools at the moment of their discard (thus affecting the morphological variability of stone tool assemblages observed through time). Amount of curation can also relate to raw material sources, with more curated artifacts coming from longer distances. Curation also relates to the selection of technological products for more intensive retouch, or shifts in technological strategies of transport, thus informing about the cultural choices and patterns of past human groups. Finally, curation also relates to tool use and use-wear analysis.   

Because of these reasons, predicting original scraper mass is a major goal in lithic analysis. Thus far, two approaches are employed to estimate the reduction and curation undergone by a retouched artifact. The first approach uses estimations derived from direct measurements on retouch. This has led to the proposal of several indexes using different measurements, such as height of retouch, length of retouched edge or projection of the original angle [@bustos-perez_exploring_2019; @eren_defining_2005; @kuhn_geometric_1990; @morales_measuring_2015]. These indices usually provide good correlation values with mass lost, but they are usually conditioned by flake morphology, direction of retouch, or tool type (laterally retouched scrapers, endscrapers, bifacial products, etc.) and each one uses different scale ranges.    

The second approach aims at estimating original flake mass based on remaining flake features. This approach has the advantage of not being limited by tool type, direction of retouch or flake morphology. Initial work focused on controlled experiments of flake formation using different measures of flake platform (width, depth) and exterior platform angle (EPA) to estimate flake mass [@dibble_platform_1997; @dibble_effect_1995; @dibble_new_1981; @pelcin_formation_1997; @pelcin_controlled_1996]. Some of the reasons to select these features were that they usually remain unaltered in most retouched artefacts. These controlled experiments provided strong explanatory power for the formation of flakes, with flake mass being predicted with an r2 value above 0.8 [@dibble_effect_1995; @li_synthesis_2023]. However, when the same variables are used to predict mass of experimentally knapped flakes, the predictive power of the model diminishes significantly, with r2 values dropping to 0.403 [@davis_quantifying_1998] (0.224 for the same retouched flakes), and 0.384 [@shott_flake_2000]. These results meant an important drawback since, as Dibble [@dibble_comment_1998 :611] states: “controlled experiments, in spite of their elegance, objectivity and replicability, are only useful if the results obtained from them are directly applicable to archaeological materials”.    

To overcome the limitations from these results, three approaches are commonly undertaken:   

  a) Adding additional features as predictive variables. Commonly flake thickness is added [@shott_use_2017; @dogandzic_edge_2015], since it is widely considered to remain unaltered through the reduction process. Other variables, such as scar count or remaining amount of cortex, seem to improve the predictive power of models [@bustos-perez_predicting_2021; @bustos-perez_multiple_2022].   
  b) Applying new methods for measuring more accurately existing variables. Examples are the refinement on traditional manual measurements of platform [@muller_new_2016], the use of digital photographs [@braun_landscape-scale_2008], or 3D scans for measuring platform [@clarkson_estimating_2011; @maloney_experimental_2020].   
  c) Applying different families of transformations in order to favor the Gaussian distribution of values of predictors and flake mass, thus increasing the predictive power of most models. These transformations usually use the cubic root [@li_synthesis_2023; @dogandzic_edge_2015; @dogandzic_results_2020] or different logarithmic transformations [@davis_quantifying_1998; @shott_flake_2000; @bustos-perez_predicting_2021; @bustos-perez_multiple_2022; @clarkson_estimating_2011; @maloney_experimental_2020].    
  
It can be considered that these additions and improvements have provided correlation values of original flake mass on scrapers which allow for comparisons at the assemblage level. However, estimations at the individual stone artifact level remain unsatisfactory with a limited application to archaeological cases.  This is due to three main reasons. First, while most research explores extensively the prediction of mass through different variables (and their interactions), it is usually not considered in the frame of continuous resharpening process, and when it is tested in this framework (continuous or single episodes of retouch), results provide lower correlation values [@dibble_comment_1998; @maloney_experimental_2020].  Second, while most research aims at estimating original flake mass, less research provides results of estimations of percentage of mass lost against actual percentage of mass lost during retouch, which is the key component of the curated concept [@shott_measuring_2007; @shott_exegesis_1996]. Third, most archaeological research addressing the prediction of original flake/scraper mass result in equations which might be difficult to extrapolate and practically apply other archaeological assemblages [@shott_use_2017; @davis_quantifying_1998; @morales_distribution_2016]. Recently [@bustos-perez_predicting_2021; @bustos-perez_multiple_2022], the use of machine learning has allowed the implementation of feature selection (identification of how many and which variables are better for prediction) and new algorithms. However, it has also resulted in limited improvements of the correlation coefficient [@bustos-perez_multiple_2022], indicating that a possible threshold limit for this approach is being reached.    

A new framework is needed to overcome the limitations of previous models (absence of being tested in sequential experimentations, higher accuracy, and easy implementation for all lithic analysts) aimed at predicting original flake mass from scraper attributes and being able to reach the individual scraper level. In the present study 134 flakes were successively retouched, providing a dataset of 694 episodes of resharpening. After each retouch episode, a series of attributes were measured and used to train four machine learning models. A Random Forest model provided the highest r2 value (0.974) when estimating scraper original mass, and the highest r2 (0.839) when estimating percentage of mass lost by retouch. The Random Forest model and all training data are implemented through a Shiny app “Original Scraper Mass Calculator v.1.0”, which allows the user to manually introduce the data from a scraper to estimate its original mass or to upload all data at once and download the results.    

## **Materials and methods.**   

### **Experimental sample.**  
  
The analyzed sample consisted of 134 experimentally knapped flakes using hard hammer. The raw material of hammerstones varied widely (quartz, quartzite, sandstone, and limestone), which allowed for a diverse range of morphologies and potential active percussion areas. The experimental sample is dominated by flakes with feather terminations (n = 121; 90.3%), followed by flakes with hinge terminations (n = 10; 7.46%).    

```{r load-data-libraries, warning=FALSE, message=FALSE}
Data1 <- read.csv("Data/Data1.csv", sep = " ")
load("Data/Data2.RData")
library(tidyverse); library(caret)
```


Initial flake mass was recorded using a Sytech SY-BS502 with a precision of 0.01 grams. Average weight of the samples was 47.38 g, with 50% of flakes weighing between 18.07 and 63.16 g, and a standard deviation of 36.48. Figure 1 presents the flake mass distribution for the experimental sample, indicating a long tail of 14 flakes weighing more than 100 g.   

The transversal section of flakes is considered to have an important effect on estimations derived from the geometric index of unifacial reduction (GIUR) [@kuhn_geometric_1990] and height of retouch. In particular, when a flake’s dorsal surface is parallel to the ventral surface, the GIUR and height of retouch will only marginally or will not at all increase after each resharpening episode, resulting in underestimations of flake mass removal [@dibble_middle_1995; @eren_kuhns_2009]. However, the actual effect of the “flat flake problem” on the estimation of flake mass might be marginal [@hiscock_reality_2009; @hiscock_experimental_2005]. The present study recorded flake schematic transversal section prior to retouch of each flake, with possible categories being: circular (n = 20), triangular (n = 63), triangular asymmetric (n = 29), trapezoidal (n = 13) and trapezoidal asymmetric (n = 9). The first three categories are considered to represent cases where the “flat flake problem” is not present, while the latter two are consider to represent cases were this problem is present.

```{r}
Data0 <- read.csv("Data/Data0.csv", sep = ",")

Summary_Assem <- data.frame(
  rbind(data.frame(data.matrix(summary(Data0$L.mm))) %>% t(),
        data.frame(data.matrix(summary(Data0$W.mm))) %>% t(),
        data.frame(data.matrix(summary(Data0$T.mm))) %>% t(),
        data.frame(data.matrix(summary(Data0$Max.Thick.mm))) %>% t(),
        data.frame(data.matrix(summary(Data0$Mean.Edge.Angle.Selected.ret))) %>% t()))
Measure <- c("Length", "Width", "Middle Thickness", "Maximum thick",
             "Mean angle edge prior to retouch")
Summary_Assem <- cbind(Measure, Summary_Assem)
rownames(Summary_Assem) <- 1:nrow(Summary_Assem)
print(Summary_Assem)
rm(Data0)
```

```{r histogram-initial-mass}
Data1 %>% 
  filter(Episode == 0) %>% 
  ggplot(aes(Or.Weight.g)) +
  geom_histogram(binwidth = 10,
                 color = "black", fill = "gray", 
                 boundary = 0) +
  theme_light() +
  ylab("Frequency") +
  xlab("Mass (g)") +
  scale_x_continuous(breaks = seq(0, 210, 10)) +
  scale_y_continuous(breaks = seq(0, 30, 2)) +
  theme(
    axis.text = element_text(color = "black", size = 6),
    axis.title = element_text(color = "black", size = 10, face = "bold"))
```
\ 

All flakes were retouched until they were too small to hold while retouching (n = 4), they broke during retouch (n = 74), or the angle of retouch was too abrupt to detach additional resharpening flakes (n = 59). Retouch was done through freehand direct hard hammer on the dorsal face of flakes (direct retouch). In order to reshape the flakes one continuous retouched edge was established. After the first episode of resharpening, the retouched edge was expanded through the flakes edge in a continuous manner. This limits the potential application of this index to simple scrapers with direct retouch (which excludes double scrapers or scrapers with inverse or bifacial retouch).   

Most flakes underwent between four and seven episodes of retouch (67.2%), while only seven flakes provided nine or more episodes of retouch. The experimental assemblage provided a total of 694 resharpening episodes with which to train the predictive models.   

### **Feature selection.**    

Based on previous research [@kuhn_geometric_1990; @dogandzic_edge_2015; @bustos-perez_predicting_2021; @hiscock_experimental_2005] variables were recorded as predictive features. After each episode of retouch, the following variables were recorded:    

  * Remaining scraper mass, recorded in grams with a Sytech SY-BS502 scale and a precision of 0.01 g. This variable is selected since machine learning models will consider remaining flake mass as a baseline on minimum mass of the scraper.   
  * Thickness at the midpoint of the flake (measured in mm with a precision of 0.1). It is considered that thickness remains relatively unchanged as resharpening increases [@shott_use_2017], and its addition tends to increase the predictive power of models [@dogandzic_edge_2015].   
  * Maximum thickness of the flake measured in mm (with a precision of 0.1). Feature selection through all possible combination of variables indicates that the logarithmic (base 10) transformation of this variable can increase the predictive power of regression models for freehand knapped flakes. Logarithmic transformation can result in Gaussian distribution of feature values increasing the predictive power of a model [@bustos-perez_predicting_2021]. It is also considered that as resharpening proceeds, the thickness at the midpoint will be displaced (since length and width will diminish), while maximum thickness will remain more stable.   
  * Three equidistant measures of height of retouch (*t*) and the corresponding thickness (*T*) of the flake [@hiscock_experimental_2005] measured in mm (with a precision of 0.1). The average of these three points is used as a predictive feature. Here it is considered that the average height of the retouch will serve as a proxy of mass removed from the scrapper.    
  * The GIUR index proposed by Kuhn [@kuhn_geometric_1990]. This index divides the height of retouch (*t*) by its corresponding thickness (*T*). As previously indicated, the present study records three equidistant heights of retouch (*t*), each being divided by their corresponding flake thickness (*T*). The GIUR value is calculated as the average of these three divisions. GIUR values can range from 0 (unretouched flake) to 1 (when the height of the reaches the dorsal side of a flake).    
Variables selected for training the regression models were: scraper mass, maximum thickness (log transformed), average height of retouch (t) and value of the GIUR index.   

### **2.3	Regression models and evaluation.**    

Four methods were employed for regression analysis: multiple linear regression, support vector regression with a linear kernel, random forest and gradient boosting machine.    

Multiple linear regression (MLR) extends the simple linear regression in such a way that it can directly accommodate multiple predictors [james_introduction_2013 : 71].    




## **References**   

</div> 



